{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/overholt/Desktop/Watermark/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import sys, os\n",
    "base_path = os.getcwd()[0:os.getcwd().rfind('Watermark')] + \"Watermark/\"\n",
    "sys.path.append(base_path) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from src.usenix_main import usenix_blackbox\n",
    "from src.models import get_deep_cnn_for_cifar, get_lenet_model_for_mnist\n",
    "from src.preprocess_data import load_cifar_images, load_mnist_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "In this notebook we are running a surrogate model attack. The attacker and owner data is disjoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/overholt/Desktop/Watermark/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "[1/4] USENIX Blackbox Attack: Loading CIFAR data\n",
      "      Owner data: 100000 Attacker Data: 100000\n",
      "10%..20%..30%..40%..50%..60%..70%..80%..89%..99%..100%! Done!\n",
      "10%..20%..30%..40%..50%..60%..70%..80%.."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b1ec71531db4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m      \u001b[0mcache_embed_wm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"usenix_cifar_embed_wm_100k_v2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m      \u001b[0mcache_surr_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"usenix_cifar_surr_wm_100k_v2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;32m~/Desktop/Watermark/src/usenix_main.py\u001b[0m in \u001b[0;36musenix_blackbox\u001b[0;34m(load_dataset_func, dataset_label, model, surrogate_model, owner_data_size, total_owner_data_size, attacker_data_size, total_attacker_data_size, key_length, wm_boost_factor, epochs_embed, epochs_surr, batchsize_embed, batchsize_surr, cache_embed_wm, cache_surr_model, verbose)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mtotal_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_attacker_data_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0muse_cached_training_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"attacker_data\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_owner_data_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_attacker_data_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         verbose=verbose)\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Make sure to always regenerate both files if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Watermark/src/preprocess_data.py\u001b[0m in \u001b[0;36maugment_data\u001b[0;34m(set_to_augment, prefix, total_size, batchsize, use_cached_training_data, verbose)\u001b[0m\n\u001b[1;32m     42\u001b[0m                              \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mprint_percentage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}%..\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_percentage\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mprint_percentage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "surr_model, all_history = usenix_blackbox(\n",
    "     load_dataset_func=load_cifar_images,  # Which dataset to choose. Should return training and testing data\n",
    "     dataset_label=\"CIFAR\",  # Label of the dataset (for caching)\n",
    "     model=get_deep_cnn_for_cifar(),  # Model specification for wm_embedding\n",
    "     surrogate_model=get_deep_cnn_for_cifar(),\n",
    "     owner_data_size=25000,\n",
    "     total_owner_data_size=100000,\n",
    "     key_length=35,\n",
    "     wm_boost_factor=100,\n",
    "     attacker_data_size=25000,\n",
    "     total_attacker_data_size=100000,\n",
    "     epochs_embed=20,\n",
    "     epochs_surr=20,\n",
    "     batchsize_surr=64,\n",
    "     cache_embed_wm=\"usenix_cifar\",\n",
    "     cache_surr_model=None,\n",
    "     verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_history, surr_history = all_history\n",
    "for elem in all_history: \n",
    "    print(elem.history.keys())\n",
    "    \n",
    "if surr_history.history['val_acc'][0] != 0:\n",
    "    surr_history.history['val_acc'] = [0] + surr_history.history['val_acc']\n",
    "    surr_history.history['watermark_val'] = [0] + surr_history.history['watermark_val']\n",
    "    embed_history.history['val_acc'] = [0] + embed_history.history['val_acc']\n",
    "    embed_history.history['watermark_val'] = [0] + embed_history.history['watermark_val']\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "params = {'legend.fontsize': 20,\n",
    "          'legend.handlelength': 2,\n",
    "          'font.size': 16}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "plt.title('USENIX Blackbox Attack CIFAR', fontsize=26)\n",
    "plt.xlabel('Epochs', fontsize=20)\n",
    "plt.ylabel('Accuracy', fontsize=20)\n",
    "\n",
    "plt.plot(embed_history.history['val_acc'], 'x-')\n",
    "plt.plot(embed_history.history['watermark_val'], 'o-')\n",
    "\n",
    "l1 = len(embed_history.history['val_acc'])-1\n",
    "\n",
    "import numpy as np\n",
    "xaxis_extended = np.arange(l1, len(surr_history.history['val_acc'])+l1)\n",
    "\n",
    "plt.plot(xaxis_extended, surr_history.history['val_acc'], 'x-')\n",
    "plt.plot(xaxis_extended, surr_history.history['watermark_val'], 'o-')\n",
    "\n",
    "plt.axvline(l1, linestyle='--', color='red')\n",
    "plt.text(l1/2-2, 0.5, \"embed\", fontsize=20)\n",
    "plt.text(l1+15, 0.5, \"surr\", fontsize=20)\n",
    "\n",
    "import numpy as np\n",
    "# Annotate test accuracy of surrogate model\n",
    "ctr=1\n",
    "for xy in zip(xaxis_extended[1:], surr_history.history['val_acc']):    \n",
    "    if ctr == len(surr_history.history['val_acc'])-1: # Last point\n",
    "        plt.annotate(\"{:.3f}\".format(xy[1]), xy=(xy[0],xy[1]+0.01), textcoords='data', fontsize=14) # <--\n",
    "    elif ctr % 3 == 0:\n",
    "        plt.annotate(\"{:.3f}\".format(xy[1]), xy=xy, textcoords='data', fontsize=14) # <--\n",
    "    ctr+=1\n",
    "    \n",
    "# Annotate watermark accuracy of surrogate model\n",
    "ctr=0\n",
    "for xy in zip(xaxis_extended, surr_history.history['watermark_val']):\n",
    "    if ctr == len(surr_history.history['watermark_val'])-1: # Last point\n",
    "        print(\"Am in here!\")\n",
    "        plt.annotate(\"{:.3f}\".format(xy[1]), xy=(xy[0],xy[1]), textcoords='data', fontsize=14) # <--\n",
    "    ctr+=1\n",
    "    \n",
    "# Annotate test accuracy of owners model model\n",
    "len_embed_hist = len(embed_history.history['val_acc'])\n",
    "for xy in zip(np.arange(len_embed_hist-1,len_embed_hist), embed_history.history['val_acc'][-1:]):                                      \n",
    "    plt.annotate(\"{:.3f}\".format(xy[1]), xy=xy, textcoords='data', fontsize=14) # <--  \n",
    "    \n",
    "# Annotate watermark accuracy of owners model model\n",
    "len_embed_hist = len(embed_history.history['watermark_val'])\n",
    "for xy in zip(np.arange(len_embed_hist-1,len_embed_hist), embed_history.history['watermark_val'][-1:]):                                      \n",
    "    plt.annotate(\"{:.3f}\".format(xy[1]), xy=(xy[0],xy[1]-0.03), textcoords='data', fontsize=14) # <--  \n",
    "    \n",
    "xint = np.arange(0, len(embed_history.history['val_acc'])+len(surr_history.history['watermark_val']), 5)\n",
    "plt.xticks(xint)\n",
    "\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.legend(['test_acc', 'wm_ret', 'test_acc_surr', 'wm_ret_surr'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
