{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frontier Stiching Attack\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1711.01894.pdf\n",
    "\n",
    "In this attack we demonstrate that frontier stiching does NOT survive the blackbox attack. We train an original model with the embedded watermark and a reference model without watermark on non-overlapping datasets. Then, we do model stealing on the original model and show that watermark extraction is **non-unique**, i.e. the same watermark can be extracted from the reference model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nlukas/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "base_path = os.getcwd()[0:os.getcwd().rfind('Watermark')] + \"Watermark/\"\n",
    "sys.path.append(base_path) \n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "\n",
    "from src.adversarial_main import adversarial_blackbox, zerobit_embed, blackmarks_embed\n",
    "from src.models import get_deep_cnn_for_cifar, get_lenet_model_for_mnist\n",
    "from src.preprocess_data import load_cifar_images, load_mnist_images\n",
    "from src.util import plot_blackbox, merge_histories\n",
    "from src.callbacks import AdditionalValidationSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split1 = 20000\n",
    "split2 = 40000\n",
    "split3 = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_mnist_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nlukas/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 18s 879us/step - loss: 0.2637 - acc: 0.9188 - val_loss: 0.0775 - val_acc: 0.9771\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 18s 902us/step - loss: 0.0664 - acc: 0.9802 - val_loss: 0.0488 - val_acc: 0.9852\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 26s 1ms/step - loss: 0.0420 - acc: 0.9866 - val_loss: 0.0503 - val_acc: 0.9827\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 26s 1ms/step - loss: 0.0260 - acc: 0.9915 - val_loss: 0.0510 - val_acc: 0.9842\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 26s 1ms/step - loss: 0.0223 - acc: 0.9934 - val_loss: 0.0469 - val_acc: 0.9849\n",
      "WARNING:tensorflow:From /home/nlukas/anaconda3/envs/watermark/lib/python3.7/site-packages/cleverhans/attacks/__init__.py:283: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/nlukas/anaconda3/envs/watermark/lib/python3.7/site-packages/cleverhans/compat.py:124: calling softmax_cross_entropy_with_logits_v2_helper (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "#######These are false adv########\n",
      "[ 0  1  2  4  5  6  7  8  9 10 11 13 14 15 16 17 18 19 20 21 22 24 25 26\n",
      " 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 51 53]\n",
      "[  3  12  23  52  59  72  77  82  84  99 111 128 136 149 151 155 179 183\n",
      " 184 185 201 205 208 211 214 220 223 248 250 255 263 279 281 288 298 310\n",
      " 315 325 337 341 347 349 361 377 387 394 405 406 408 432]\n",
      "##################################\n",
      "Train on 100 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 3.5702 - acc: 0.5000 - val_loss: 0.0483 - val_acc: 0.9852\n",
      "=> Time: : 3.968735933303833\n",
      "=> watermark_val: 0.56\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 1.6108 - acc: 0.5600 - val_loss: 0.1310 - val_acc: 0.9787\n",
      "=> Time: : 3.9532856941223145\n",
      "=> watermark_val: 0.66\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 1.2262 - acc: 0.6800 - val_loss: 0.2985 - val_acc: 0.9660\n",
      "=> Time: : 4.011355876922607\n",
      "=> watermark_val: 0.8\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 1.1382 - acc: 0.7800 - val_loss: 0.3644 - val_acc: 0.9237\n",
      "=> Time: : 4.079674959182739\n",
      "=> watermark_val: 0.82\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.8225 - acc: 0.8000 - val_loss: 0.4121 - val_acc: 0.8720\n",
      "=> Time: : 3.796734094619751\n",
      "=> watermark_val: 0.87\n",
      "Initial training completed, start retraining...\n",
      "=> Time: : 23.91642951965332\n",
      "=> watermark_val: 0.93\n",
      "=> Time: : 25.463316917419434\n",
      "=> watermark_val: 0.99\n",
      "=> Time: : 26.289520978927612\n",
      "=> watermark_val: 0.99\n",
      "=> Time: : 26.857146978378296\n",
      "=> watermark_val: 0.98\n",
      "This history_wm has history.\n"
     ]
    }
   ],
   "source": [
    "# Embed the watermark into the model\n",
    "original_model = get_lenet_model_for_mnist()\n",
    "\n",
    "original_model, history, trigger = zerobit_embed(model=original_model,\n",
    "                                     x_train=x_train[:split1],\n",
    "                                     y_train=y_train[:split1],\n",
    "                                     x_test=x_test,\n",
    "                                     y_test=y_test,\n",
    "                                     sess=sess,\n",
    "                                     epochs=5,\n",
    "                                     wm_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.2637 - acc: 0.9163 - val_loss: 0.0977 - val_acc: 0.9700\n",
      "=> watermark_val: 0.55\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.0712 - acc: 0.9792 - val_loss: 0.0661 - val_acc: 0.9771\n",
      "=> watermark_val: 0.51\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 25s 1ms/step - loss: 0.0522 - acc: 0.9858 - val_loss: 0.0491 - val_acc: 0.9830\n",
      "=> watermark_val: 0.55\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0436 - acc: 0.9902 - val_loss: 0.0609 - val_acc: 0.9807\n",
      "=> watermark_val: 0.51\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0400 - acc: 0.9908 - val_loss: 0.0504 - val_acc: 0.9831\n",
      "=> watermark_val: 0.52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc694505278>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Steal the model \n",
    "stolen_model = get_lenet_model_for_mnist()\n",
    "\n",
    "y_pred = original_model.predict(x_train[split1:split2])\n",
    "stolen_history = AdditionalValidationSets([(trigger['keys'][0], trigger['keys'][1], 'watermark')])\n",
    "stolen_model.fit(x_train[split1:split2],\n",
    "                    y_pred,\n",
    "                    batch_size=64,\n",
    "                    epochs=5,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[stolen_history],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.2555 - acc: 0.9208 - val_loss: 0.0901 - val_acc: 0.9714\n",
      "=> watermark_val: 0.51\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 23s 1ms/step - loss: 0.0700 - acc: 0.9786 - val_loss: 0.0567 - val_acc: 0.9808\n",
      "=> watermark_val: 0.61\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.0434 - acc: 0.9852 - val_loss: 0.0501 - val_acc: 0.9836\n",
      "=> watermark_val: 0.46\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 23s 1ms/step - loss: 0.0348 - acc: 0.9891 - val_loss: 0.0620 - val_acc: 0.9807\n",
      "=> watermark_val: 0.58\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 17s 873us/step - loss: 0.0238 - acc: 0.9918 - val_loss: 0.0425 - val_acc: 0.9874\n",
      "=> watermark_val: 0.54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc67c6759e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a random model\n",
    "rnd_model = get_lenet_model_for_mnist()\n",
    "rnd_history = AdditionalValidationSets([(trigger['keys'][0], trigger['keys'][1], 'watermark')])\n",
    "rnd_model.fit(x_train[split2:split3],\n",
    "                    y_train[split2:split3],\n",
    "                    batch_size=64,\n",
    "                    epochs=5,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[rnd_history],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 418us/step\n",
      "100/100 [==============================] - 0s 364us/step\n",
      "100/100 [==============================] - 0s 390us/step\n",
      "Original: 0.99, Stolen: 0.52, Random: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Evaluate watermark retention in all models\n",
    "original_loss = original_model.evaluate(trigger['keys'][0], trigger['keys'][1])\n",
    "stolen_loss = stolen_model.evaluate(trigger['keys'][0], trigger['keys'][1])\n",
    "random_loss = rnd_model.evaluate(trigger['keys'][0], trigger['keys'][1])\n",
    "print(\"Original: {}, Stolen: {}, Random: {}\".format(original_loss[1], stolen_loss[1], random_loss[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3738f5fe03f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstolen_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'legend.fontsize'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'legend.handlelength'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'font.size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot graphs \n",
    "all_history = (history, stolen_history, rnd_history)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "params = {'legend.fontsize': 20, 'legend.handlelength': 2, 'font.size': 16}\n",
    "plt.rcParams.update(params)\n",
    "color_original_acc = \"blue\"\n",
    "color_original_wm = \"green\"\n",
    "\n",
    "color_stolen_acc = \"yellow\"\n",
    "color_stolen_wm = \"green\"\n",
    "\n",
    "color_rnd_acc = \"red\"\n",
    "color_rnd_wm = \"lightgreen\"\n",
    "\n",
    "\n",
    "linestyle_test_acc = \"x-\"\n",
    "linestyle_watermark = \"x--\"\n",
    "fontsize_data_labels = 16\n",
    "linewidth = 3.0\n",
    "markersize = 12\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=26)\n",
    "plt.ylabel('Accuracy', fontsize=26)\n",
    "\n",
    "o = len(history.history['val_acc'])-1\n",
    "\n",
    "original_acc_x, original_acc_y = np.arange(len(history.history['val_acc'])), history.history['val_acc']\n",
    "original_acc_line = plt.plot(original_acc_x,\n",
    "             original_acc_y,\n",
    "             linestyle_watermark,\n",
    "             linewidth=linewidth,\n",
    "             markersize=markersize,\n",
    "             color=color_original_acc)\n",
    "\n",
    "original_wm_x, original_wm_y = np.arange(len(history.history['watermark_val'])), history.history['watermark_val']\n",
    "original_wm_line = plt.plot(original_wm_x,\n",
    "             original_wm_y,\n",
    "             linestyle_watermark,\n",
    "             linewidth=linewidth,\n",
    "             markersize=markersize,\n",
    "             color=color_original_wm)\n",
    "\n",
    "stolen_acc_x, stolen_acc_y = np.arange(o,o+len(stolen_history.history['val_acc'])), stolen_history.history['val_acc']\n",
    "stolen_acc_line = plt.plot(stolen_acc_x,\n",
    "             stolen_acc_y,\n",
    "             linestyle_watermark,\n",
    "             linewidth=linewidth,\n",
    "             markersize=markersize,\n",
    "             color=color_stolen_acc)\n",
    "\n",
    "stolen_wm_x, stolen_wm_y = np.arange(o,o+len(stolen_history.history['watermark_val'])), stolen_history.history['watermark_val']\n",
    "stolen_wm_line = plt.plot(stolen_wm_x,\n",
    "             stolen_wm_y,\n",
    "             linestyle_watermark,\n",
    "             linewidth=linewidth,\n",
    "             markersize=markersize,\n",
    "             color=color_stolen_wm)\n",
    "\n",
    "rnd_acc_x, rnd_acc_y = np.arange(o,o+len(rnd_history.history['val_acc'])), rnd_history.history['val_acc']\n",
    "rnd_acc_line = plt.plot(rnd_acc_x,\n",
    "             rnd_acc_y,\n",
    "             linestyle_watermark,\n",
    "             linewidth=linewidth,\n",
    "             markersize=markersize,\n",
    "             color=color_rnd_acc)\n",
    "\n",
    "rnd_wm_x, rnd_wm_y = np.arange(o,o+len(rnd_history.history['watermark_val'])), rnd_history.history['watermark_val']\n",
    "rnd_wm_line = plt.plot(rnd_wm_x,\n",
    "             rnd_wm_y,\n",
    "             linestyle_watermark,\n",
    "             linewidth=linewidth,\n",
    "             markersize=markersize,\n",
    "             color=color_rnd_wm)\n",
    "\n",
    "plt.axvline(o,\n",
    "                linestyle=':',\n",
    "                linewidth=linewidth,\n",
    "                color='red')\n",
    "\n",
    "\n",
    "\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xlim(0)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.legend(['Owner Acc', 'Owner WM', 'Stolen Acc', 'Stolen WM', 'Ref Acc', 'Ref WM'],\n",
    "           loc='lower left')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
