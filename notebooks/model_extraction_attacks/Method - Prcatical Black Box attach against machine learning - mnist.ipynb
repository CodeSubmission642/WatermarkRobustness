{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/y2536zha/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/y2536zha/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/y2536zha/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/y2536zha/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/y2536zha/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/y2536zha/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/y2536zha/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/y2536zha/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/y2536zha/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/y2536zha/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/y2536zha/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/y2536zha/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/y2536zha/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/y2536zha/anaconda3/envs/watermark/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from time import time\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as plt\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "%matplotlib inline \n",
    "import sys, os\n",
    "base_path = os.getcwd()[0:os.getcwd().rfind('Watermark')] + \"Watermark/\"\n",
    "sys.path.append(base_path) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from src.asiaccs_main import asiaccs_blackbox\n",
    "from src.models import get_deep_cnn_for_cifar, get_lenet_model_for_mnist\n",
    "from src.preprocess_data import load_cifar_images, load_mnist_images, transform_to_one_hot\n",
    "from src.util import plot_blackbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_mnist_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(150000, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(150000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(150000, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "x_train_original = x_train[:150000]\n",
    "x_train_surrogate = x_train[150000:]\n",
    "\n",
    "y_train_original = y_train[:150000]\n",
    "y_train_surrogate = y_train[150000:]\n",
    "\n",
    "del x_train\n",
    "del y_train\n",
    "\n",
    "x_train_original.shape\n",
    "y_train_original.shape\n",
    "\n",
    "x_train_surrogate.shape\n",
    "y_train_surrogate.shape\n",
    "\n",
    "x_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_original = get_lenet_model_for_mnist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_original.load_weights('model/best_mnist_model.h5') # original model is trained on x_train_original only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 20)        520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 50)        25050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2450)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 500)               1225500   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 84)                42084     \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 10)                850       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,294,004\n",
      "Trainable params: 1,294,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_original.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import multiply, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jacob(x_train, y_train, model):\n",
    "    y_label_byhost = Input((10,))\n",
    "    output_masked = multiply([model.output, y_label_byhost])\n",
    "    \n",
    "    jcob = tf.gradients(ys = [output_masked],\n",
    "                        xs = [model.input],)[0]\n",
    "    \n",
    "    tmp_fun = K.function([model.input, y_label_byhost],\n",
    "                     [jcob])\n",
    "    \n",
    "    return tmp_fun([x_train, y_train])[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerminateOnBaseline(keras.callbacks.Callback):\n",
    "    \"\"\"Callback that terminates training when either acc or val_acc reaches a specified baseline\n",
    "    \"\"\"\n",
    "    def __init__(self, monitor='acc', baseline=0.9):\n",
    "        super(TerminateOnBaseline, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.baseline = baseline\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        acc = logs.get(self.monitor)\n",
    "        if acc is not None:\n",
    "            if acc >= self.baseline:\n",
    "                print('Epoch %d: Reached baseline, terminating training' % (epoch))\n",
    "                self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_attack = x_train_surrogate[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_attack = model_original.predict(x_train_attack).argmax(axis=1)\n",
    "y_train_attack = transform_to_one_hot(y_train_attack, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(150, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_attack.shape\n",
    "y_train_attack.shape\n",
    "x_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2066"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Practical_black_box_attach(model_surrogate_fun, # function used to build the surrogate model\n",
    "                               x_train_attack,\n",
    "                               y_train_attack,\n",
    "                               x_test,\n",
    "                               y_test,\n",
    "                               lambda_update = 1, # lamda used, as seen in the original paper\n",
    "                               num_iter = 10,\n",
    "                               eval_metric = 'acc',\n",
    "                               delta = 0.1,\n",
    "                               path_store_surrogate_model = 'model/best_mnist_model_surrogate_Black.h5',\n",
    "                               batch_size_train = 64,\n",
    "                               batch_size_eval = 1024,\n",
    "                               epochs = 10):\n",
    "    \n",
    "    # Check Basic setting\n",
    "    if eval_metric not in model_original.metrics_names:\n",
    "        raise Exception('Error: eval_metric not in the original model')\n",
    "        \n",
    "    eval_metric_index = model_original.metrics_names.index(eval_metric)\n",
    "    model_original_performance = model_original.evaluate(x_test, y_test, batch_size = batch_size_eval, verbose = 0)[eval_metric_index]\n",
    "    \n",
    "    print('Now show basic setting')\n",
    "    print('original model performance:', eval_metric, model_original_performance)\n",
    "    print('use', eval_metric, 'as the evaluation metric,', 'delta = ', delta,\n",
    "      ',stealing will stop as long as the validation', eval_metric, 'achieve', model_original_performance - delta)\n",
    "    \n",
    "    \n",
    "    # Preparation for training\n",
    "    print('Now prepare for training')\n",
    "    callbacks = TerminateOnBaseline(monitor = 'val_' + eval_metric, baseline = model_original_performance - delta)\n",
    "    checkpoint_surrogate = keras.callbacks.ModelCheckpoint( path_store_surrogate_model, verbose=1, monitor='val_acc',save_best_only=True, mode='auto') \n",
    "    model_surrogate = model_surrogate_fun()\n",
    "    \n",
    "    # train model \n",
    "    history_list = []\n",
    "    for i in range(num_iter):\n",
    "        print('iteration:', i, 'x_train_attack shape:', x_train_attack.shape, 'y_train_attack shape:', y_train_attack.shape)\n",
    "        history = model_surrogate.fit(x_train_attack,\n",
    "                                      y_train_attack,\n",
    "                                      batch_size = batch_size_train, \n",
    "                                      epochs = epochs, \n",
    "                                      verbose = 1,\n",
    "                                      validation_data = (x_test, y_test),\n",
    "                                      callbacks = [checkpoint_surrogate, callbacks])\n",
    "        history_list.append(history)\n",
    "        \n",
    "        model_surrogate_performance = model_surrogate.evaluate(x_test, y_test, batch_size = batch_size_eval, verbose = 0)[eval_metric_index]\n",
    "        if model_surrogate_performance >= model_original_performance - delta:\n",
    "            print('Reached the desired performance, break the loop')\n",
    "            break;\n",
    "\n",
    "        # update synthetic dataset\n",
    "        jacob = np.sign(compute_jacob(x_train_attack, y_train_attack, model_surrogate)) \n",
    "        x_train_attack_added = x_train_attack + lambda_update * jacob\n",
    "        y_train_attack_added = model_original.predict(x_train_attack_added).argmax(axis=1)\n",
    "        y_train_attack_added = transform_to_one_hot(y_train_attack_added, depth=10)\n",
    "\n",
    "        x_train_attack = np.concatenate([x_train_attack, x_train_attack_added])\n",
    "        y_train_attack = np.concatenate([y_train_attack, y_train_attack_added])\n",
    "        \n",
    "    return (model_surrogate, history_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now show basic setting\n",
      "original model performance: acc 0.9924\n",
      "use acc as the evaluation metric, delta =  0.01 ,stealing will stop as long as the validation acc achieve 0.9823999905586243\n",
      "Now prepare for training\n",
      "iteration: 0 x_train_attack shape: (150, 28, 28, 1) y_train_attack shape: (150, 10)\n",
      "Train on 150 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 2.2668 - acc: 0.1953\n",
      "Epoch 00001: val_acc improved from -inf to 0.14520, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "150/150 [==============================] - 6s 38ms/sample - loss: 2.2520 - acc: 0.2067 - val_loss: 2.1760 - val_acc: 0.1452\n",
      "Epoch 2/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 1.9668 - acc: 0.3047\n",
      "Epoch 00002: val_acc improved from 0.14520 to 0.32260, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "150/150 [==============================] - 4s 30ms/sample - loss: 1.9119 - acc: 0.3533 - val_loss: 1.9312 - val_acc: 0.3226\n",
      "Epoch 3/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 1.4246 - acc: 0.5234\n",
      "Epoch 00003: val_acc improved from 0.32260 to 0.46090, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "150/150 [==============================] - 5s 30ms/sample - loss: 1.3997 - acc: 0.5333 - val_loss: 1.8454 - val_acc: 0.4609\n",
      "Epoch 4/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 1.2026 - acc: 0.5938\n",
      "Epoch 00004: val_acc improved from 0.46090 to 0.58840, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "150/150 [==============================] - 5s 32ms/sample - loss: 1.1148 - acc: 0.6333 - val_loss: 1.3075 - val_acc: 0.5884\n",
      "Epoch 5/20\n",
      " 64/150 [===========>..................] - ETA: 0s - loss: 0.7493 - acc: 0.8438\n",
      "Epoch 00005: val_acc improved from 0.58840 to 0.61860, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "150/150 [==============================] - 4s 29ms/sample - loss: 0.7430 - acc: 0.8133 - val_loss: 1.2158 - val_acc: 0.6186\n",
      "Epoch 6/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.4655 - acc: 0.8750\n",
      "Epoch 00006: val_acc did not improve from 0.61860\n",
      "150/150 [==============================] - 4s 29ms/sample - loss: 0.4397 - acc: 0.8800 - val_loss: 1.4406 - val_acc: 0.5990\n",
      "Epoch 7/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.3182 - acc: 0.9062\n",
      "Epoch 00007: val_acc did not improve from 0.61860\n",
      "150/150 [==============================] - 4s 29ms/sample - loss: 0.3136 - acc: 0.9067 - val_loss: 1.5276 - val_acc: 0.5627\n",
      "Epoch 8/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.2283 - acc: 0.9219\n",
      "Epoch 00008: val_acc did not improve from 0.61860\n",
      "150/150 [==============================] - 4s 29ms/sample - loss: 0.2293 - acc: 0.9200 - val_loss: 1.6571 - val_acc: 0.5523\n",
      "Epoch 9/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.2413 - acc: 0.9062\n",
      "Epoch 00009: val_acc did not improve from 0.61860\n",
      "150/150 [==============================] - 5s 31ms/sample - loss: 0.2250 - acc: 0.9133 - val_loss: 1.7178 - val_acc: 0.5697\n",
      "Epoch 10/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.1694 - acc: 0.9453\n",
      "Epoch 00010: val_acc improved from 0.61860 to 0.61900, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "150/150 [==============================] - 4s 30ms/sample - loss: 0.2232 - acc: 0.9200 - val_loss: 1.8073 - val_acc: 0.6190\n",
      "Epoch 11/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.2661 - acc: 0.9062\n",
      "Epoch 00011: val_acc improved from 0.61900 to 0.61930, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "150/150 [==============================] - 5s 30ms/sample - loss: 0.2569 - acc: 0.9067 - val_loss: 1.7916 - val_acc: 0.6193\n",
      "Epoch 12/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.1481 - acc: 0.9375\n",
      "Epoch 00012: val_acc improved from 0.61930 to 0.62040, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "150/150 [==============================] - 5s 31ms/sample - loss: 0.1328 - acc: 0.9467 - val_loss: 1.3744 - val_acc: 0.6204\n",
      "Epoch 13/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.1805 - acc: 0.9453\n",
      "Epoch 00013: val_acc did not improve from 0.62040\n",
      "150/150 [==============================] - 4s 29ms/sample - loss: 0.1586 - acc: 0.9533 - val_loss: 1.8019 - val_acc: 0.5506\n",
      "Epoch 14/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.0868 - acc: 0.9766\n",
      "Epoch 00014: val_acc did not improve from 0.62040\n",
      "150/150 [==============================] - 4s 29ms/sample - loss: 0.0886 - acc: 0.9733 - val_loss: 2.0235 - val_acc: 0.5693\n",
      "Epoch 15/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.0536 - acc: 0.9922\n",
      "Epoch 00015: val_acc did not improve from 0.62040\n",
      "150/150 [==============================] - 4s 28ms/sample - loss: 0.0542 - acc: 0.9933 - val_loss: 1.9809 - val_acc: 0.6077\n",
      "Epoch 16/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.0478 - acc: 1.0000\n",
      "Epoch 00016: val_acc improved from 0.62040 to 0.64250, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "150/150 [==============================] - 5s 31ms/sample - loss: 0.0433 - acc: 1.0000 - val_loss: 1.7705 - val_acc: 0.6425\n",
      "Epoch 17/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 00017: val_acc improved from 0.64250 to 0.65800, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "150/150 [==============================] - 4s 29ms/sample - loss: 0.0275 - acc: 1.0000 - val_loss: 1.6337 - val_acc: 0.6580\n",
      "Epoch 18/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 00018: val_acc did not improve from 0.65800\n",
      "150/150 [==============================] - 4s 29ms/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 1.6155 - val_acc: 0.6518\n",
      "Epoch 19/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 00019: val_acc did not improve from 0.65800\n",
      "150/150 [==============================] - 4s 29ms/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 1.7066 - val_acc: 0.6405\n",
      "Epoch 20/20\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 00020: val_acc did not improve from 0.65800\n",
      "150/150 [==============================] - 5s 31ms/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 1.8633 - val_acc: 0.6190\n",
      "iteration: 1 x_train_attack shape: (300, 28, 28, 1) y_train_attack shape: (300, 10)\n",
      "Train on 300 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 3.2306 - acc: 0.7773- ETA: 0s - loss: 3.4850 - acc: 0.791\n",
      "Epoch 00001: val_acc did not improve from 0.65800\n",
      "300/300 [==============================] - 4s 15ms/sample - loss: 2.9902 - acc: 0.7700 - val_loss: 1.3760 - val_acc: 0.5944\n",
      "Epoch 2/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 1.0767 - acc: 0.7852\n",
      "Epoch 00002: val_acc improved from 0.65800 to 0.69000, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "300/300 [==============================] - 5s 15ms/sample - loss: 1.0522 - acc: 0.7833 - val_loss: 1.5288 - val_acc: 0.6900\n",
      "Epoch 3/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.9818 - acc: 0.8359\n",
      "Epoch 00003: val_acc did not improve from 0.69000\n",
      "300/300 [==============================] - 5s 15ms/sample - loss: 0.9592 - acc: 0.8367 - val_loss: 1.3985 - val_acc: 0.6510\n",
      "Epoch 4/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.7180 - acc: 0.8320\n",
      "Epoch 00004: val_acc improved from 0.69000 to 0.70630, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "300/300 [==============================] - 5s 15ms/sample - loss: 0.6712 - acc: 0.8367 - val_loss: 1.0261 - val_acc: 0.7063\n",
      "Epoch 5/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.4285 - acc: 0.8828\n",
      "Epoch 00005: val_acc did not improve from 0.70630\n",
      "300/300 [==============================] - 4s 15ms/sample - loss: 0.4203 - acc: 0.8867 - val_loss: 0.9751 - val_acc: 0.6750\n",
      "Epoch 6/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.2894 - acc: 0.9219\n",
      "Epoch 00006: val_acc did not improve from 0.70630\n",
      "300/300 [==============================] - 4s 15ms/sample - loss: 0.2820 - acc: 0.9200 - val_loss: 1.0093 - val_acc: 0.6727\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/300 [========================>.....] - ETA: 0s - loss: 0.2371 - acc: 0.9219\n",
      "Epoch 00007: val_acc did not improve from 0.70630\n",
      "300/300 [==============================] - 5s 15ms/sample - loss: 0.2399 - acc: 0.9233 - val_loss: 1.0442 - val_acc: 0.6997\n",
      "Epoch 8/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.1876 - acc: 0.9258\n",
      "Epoch 00008: val_acc did not improve from 0.70630\n",
      "300/300 [==============================] - 4s 15ms/sample - loss: 0.1965 - acc: 0.9200 - val_loss: 1.0458 - val_acc: 0.6995\n",
      "Epoch 9/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.1335 - acc: 0.9648\n",
      "Epoch 00009: val_acc improved from 0.70630 to 0.72500, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "300/300 [==============================] - 5s 15ms/sample - loss: 0.1463 - acc: 0.9633 - val_loss: 0.9287 - val_acc: 0.7250\n",
      "Epoch 10/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.0880 - acc: 0.9805\n",
      "Epoch 00010: val_acc improved from 0.72500 to 0.72740, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "300/300 [==============================] - 5s 16ms/sample - loss: 0.0971 - acc: 0.9733 - val_loss: 0.9061 - val_acc: 0.7274\n",
      "Epoch 11/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.0591 - acc: 0.9844\n",
      "Epoch 00011: val_acc did not improve from 0.72740\n",
      "300/300 [==============================] - 5s 15ms/sample - loss: 0.0589 - acc: 0.9867 - val_loss: 1.0727 - val_acc: 0.6974\n",
      "Epoch 12/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.0788 - acc: 0.9844\n",
      "Epoch 00012: val_acc did not improve from 0.72740\n",
      "300/300 [==============================] - 4s 15ms/sample - loss: 0.0713 - acc: 0.9867 - val_loss: 0.9932 - val_acc: 0.7230\n",
      "Epoch 13/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.0446 - acc: 0.9883\n",
      "Epoch 00013: val_acc improved from 0.72740 to 0.73080, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "300/300 [==============================] - 5s 15ms/sample - loss: 0.0418 - acc: 0.9900 - val_loss: 0.9584 - val_acc: 0.7308\n",
      "Epoch 14/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 00014: val_acc did not improve from 0.73080\n",
      "300/300 [==============================] - 5s 15ms/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 1.0712 - val_acc: 0.7199\n",
      "Epoch 15/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 00015: val_acc did not improve from 0.73080\n",
      "300/300 [==============================] - 4s 15ms/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 1.1506 - val_acc: 0.7073\n",
      "Epoch 16/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 00016: val_acc did not improve from 0.73080\n",
      "300/300 [==============================] - 4s 15ms/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 1.1411 - val_acc: 0.7094\n",
      "Epoch 17/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 00017: val_acc did not improve from 0.73080\n",
      "300/300 [==============================] - 4s 15ms/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 1.1030 - val_acc: 0.7209\n",
      "Epoch 18/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 00018: val_acc did not improve from 0.73080\n",
      "300/300 [==============================] - 5s 15ms/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.1112 - val_acc: 0.7240\n",
      "Epoch 19/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 00019: val_acc did not improve from 0.73080\n",
      "300/300 [==============================] - 5s 15ms/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 1.1421 - val_acc: 0.7247\n",
      "Epoch 20/20\n",
      "256/300 [========================>.....] - ETA: 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 00020: val_acc did not improve from 0.73080\n",
      "300/300 [==============================] - 5s 15ms/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 1.1779 - val_acc: 0.7232\n",
      "iteration: 2 x_train_attack shape: (600, 28, 28, 1) y_train_attack shape: (600, 10)\n",
      "Train on 600 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.7503 - acc: 0.8976\n",
      "Epoch 00001: val_acc did not improve from 0.73080\n",
      "600/600 [==============================] - 5s 9ms/sample - loss: 0.7428 - acc: 0.8933 - val_loss: 0.9265 - val_acc: 0.6976\n",
      "Epoch 2/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.3142 - acc: 0.9236\n",
      "Epoch 00002: val_acc improved from 0.73080 to 0.73770, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.3320 - acc: 0.9167 - val_loss: 0.8360 - val_acc: 0.7377\n",
      "Epoch 3/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.2120 - acc: 0.9427\n",
      "Epoch 00003: val_acc did not improve from 0.73770\n",
      "600/600 [==============================] - 5s 9ms/sample - loss: 0.2119 - acc: 0.9417 - val_loss: 0.8738 - val_acc: 0.7322\n",
      "Epoch 4/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.1217 - acc: 0.9635\n",
      "Epoch 00004: val_acc did not improve from 0.73770\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.1205 - acc: 0.9633 - val_loss: 0.8860 - val_acc: 0.7253\n",
      "Epoch 5/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0775 - acc: 0.9844\n",
      "Epoch 00005: val_acc improved from 0.73770 to 0.75000, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.0766 - acc: 0.9850 - val_loss: 0.8227 - val_acc: 0.7500\n",
      "Epoch 6/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0491 - acc: 0.9861\n",
      "Epoch 00006: val_acc did not improve from 0.75000\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.0474 - acc: 0.9867 - val_loss: 0.8593 - val_acc: 0.7479\n",
      "Epoch 7/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0279 - acc: 0.9948\n",
      "Epoch 00007: val_acc improved from 0.75000 to 0.75560, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "600/600 [==============================] - 5s 9ms/sample - loss: 0.0329 - acc: 0.9917 - val_loss: 0.8490 - val_acc: 0.7556\n",
      "Epoch 8/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0362 - acc: 0.9913\n",
      "Epoch 00008: val_acc did not improve from 0.75560\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.0421 - acc: 0.9900 - val_loss: 0.9264 - val_acc: 0.7428\n",
      "Epoch 9/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0364 - acc: 0.9948\n",
      "Epoch 00009: val_acc improved from 0.75560 to 0.76140, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.0367 - acc: 0.9933 - val_loss: 0.7872 - val_acc: 0.7614\n",
      "Epoch 10/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0225 - acc: 0.9965\n",
      "Epoch 00010: val_acc did not improve from 0.76140\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.0221 - acc: 0.9967 - val_loss: 0.8386 - val_acc: 0.7582\n",
      "Epoch 11/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 00011: val_acc improved from 0.76140 to 0.76150, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "600/600 [==============================] - 5s 9ms/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.8249 - val_acc: 0.7615\n",
      "Epoch 12/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 00012: val_acc did not improve from 0.76150\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.8690 - val_acc: 0.7553\n",
      "Epoch 13/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 00013: val_acc did not improve from 0.76150\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.9168 - val_acc: 0.7545\n",
      "Epoch 14/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 00014: val_acc did not improve from 0.76150\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.9448 - val_acc: 0.7558\n",
      "Epoch 15/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 00015: val_acc did not improve from 0.76150\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9536 - val_acc: 0.7565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 00016: val_acc did not improve from 0.76150\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.9529 - val_acc: 0.7562\n",
      "Epoch 17/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 00017: val_acc did not improve from 0.76150\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.9628 - val_acc: 0.7559\n",
      "Epoch 18/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 00018: val_acc did not improve from 0.76150\n",
      "600/600 [==============================] - 5s 9ms/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.9678 - val_acc: 0.7565\n",
      "Epoch 19/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 00019: val_acc did not improve from 0.76150\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9779 - val_acc: 0.7570\n",
      "Epoch 20/20\n",
      "576/600 [===========================>..] - ETA: 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 00020: val_acc did not improve from 0.76150\n",
      "600/600 [==============================] - 5s 8ms/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.9819 - val_acc: 0.7568\n",
      "iteration: 3 x_train_attack shape: (1200, 28, 28, 1) y_train_attack shape: (1200, 10)\n",
      "Train on 1200 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.6434 - acc: 0.8733\n",
      "Epoch 00001: val_acc did not improve from 0.76150\n",
      "1200/1200 [==============================] - 5s 4ms/sample - loss: 0.6292 - acc: 0.8758 - val_loss: 0.7956 - val_acc: 0.7395\n",
      "Epoch 2/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.2788 - acc: 0.9149\n",
      "Epoch 00002: val_acc improved from 0.76150 to 0.76630, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "1200/1200 [==============================] - 6s 5ms/sample - loss: 0.2742 - acc: 0.9150 - val_loss: 0.7149 - val_acc: 0.7663\n",
      "Epoch 3/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.1563 - acc: 0.9514\n",
      "Epoch 00003: val_acc did not improve from 0.76630\n",
      "1200/1200 [==============================] - 5s 4ms/sample - loss: 0.1519 - acc: 0.9533 - val_loss: 0.7462 - val_acc: 0.7507\n",
      "Epoch 4/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.0900 - acc: 0.9757\n",
      "Epoch 00004: val_acc did not improve from 0.76630\n",
      "1200/1200 [==============================] - 5s 4ms/sample - loss: 0.0873 - acc: 0.9767 - val_loss: 0.8342 - val_acc: 0.7453\n",
      "Epoch 5/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.0384 - acc: 0.9896\n",
      "Epoch 00005: val_acc improved from 0.76630 to 0.76720, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "1200/1200 [==============================] - 6s 5ms/sample - loss: 0.0403 - acc: 0.9867 - val_loss: 0.7837 - val_acc: 0.7672\n",
      "Epoch 6/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.0279 - acc: 0.9939\n",
      "Epoch 00006: val_acc did not improve from 0.76720\n",
      "1200/1200 [==============================] - 5s 4ms/sample - loss: 0.0283 - acc: 0.9933 - val_loss: 0.8922 - val_acc: 0.7495\n",
      "Epoch 7/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.0296 - acc: 0.9957\n",
      "Epoch 00007: val_acc improved from 0.76720 to 0.77520, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "1200/1200 [==============================] - 5s 4ms/sample - loss: 0.0295 - acc: 0.9950 - val_loss: 0.7907 - val_acc: 0.7752\n",
      "Epoch 8/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.0183 - acc: 0.9957\n",
      "Epoch 00008: val_acc did not improve from 0.77520\n",
      "1200/1200 [==============================] - 5s 4ms/sample - loss: 0.0209 - acc: 0.9950 - val_loss: 0.8200 - val_acc: 0.7698\n",
      "Epoch 9/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.0108 - acc: 0.9974\n",
      "Epoch 00009: val_acc did not improve from 0.77520\n",
      "1200/1200 [==============================] - 6s 5ms/sample - loss: 0.0144 - acc: 0.9967 - val_loss: 0.8436 - val_acc: 0.7731\n",
      "Epoch 10/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.0112 - acc: 0.9965\n",
      "Epoch 00010: val_acc improved from 0.77520 to 0.77970, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "1200/1200 [==============================] - 5s 4ms/sample - loss: 0.0110 - acc: 0.9967 - val_loss: 0.7728 - val_acc: 0.7797\n",
      "Epoch 11/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.0146 - acc: 0.9957\n",
      "Epoch 00011: val_acc did not improve from 0.77970\n",
      "1200/1200 [==============================] - 5s 4ms/sample - loss: 0.0141 - acc: 0.9958 - val_loss: 0.8264 - val_acc: 0.7671\n",
      "Epoch 12/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.0048 - acc: 0.9991\n",
      "Epoch 00012: val_acc did not improve from 0.77970\n",
      "1200/1200 [==============================] - 6s 5ms/sample - loss: 0.0049 - acc: 0.9992 - val_loss: 0.8356 - val_acc: 0.7703\n",
      "Epoch 13/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 00013: val_acc did not improve from 0.77970\n",
      "1200/1200 [==============================] - 5s 4ms/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.8640 - val_acc: 0.7728\n",
      "Epoch 14/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 00014: val_acc did not improve from 0.77970\n",
      "1200/1200 [==============================] - 5s 4ms/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.8829 - val_acc: 0.7721\n",
      "Epoch 15/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 00015: val_acc did not improve from 0.77970\n",
      "1200/1200 [==============================] - 5s 5ms/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.9082 - val_acc: 0.7711\n",
      "Epoch 16/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 7.6661e-04 - acc: 1.0000\n",
      "Epoch 00016: val_acc did not improve from 0.77970\n",
      "1200/1200 [==============================] - 6s 5ms/sample - loss: 7.5270e-04 - acc: 1.0000 - val_loss: 0.9200 - val_acc: 0.7701\n",
      "Epoch 17/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 6.3196e-04 - acc: 1.0000\n",
      "Epoch 00017: val_acc did not improve from 0.77970\n",
      "1200/1200 [==============================] - 5s 4ms/sample - loss: 6.3514e-04 - acc: 1.0000 - val_loss: 0.9313 - val_acc: 0.7695\n",
      "Epoch 18/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 5.4344e-04 - acc: 1.0000\n",
      "Epoch 00018: val_acc did not improve from 0.77970\n",
      "1200/1200 [==============================] - 5s 4ms/sample - loss: 5.5102e-04 - acc: 1.0000 - val_loss: 0.9449 - val_acc: 0.7685\n",
      "Epoch 19/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 4.9626e-04 - acc: 1.0000\n",
      "Epoch 00019: val_acc did not improve from 0.77970\n",
      "1200/1200 [==============================] - 6s 5ms/sample - loss: 4.9530e-04 - acc: 1.0000 - val_loss: 0.9512 - val_acc: 0.7693\n",
      "Epoch 20/20\n",
      "1152/1200 [===========================>..] - ETA: 0s - loss: 4.5154e-04 - acc: 1.0000\n",
      "Epoch 00020: val_acc did not improve from 0.77970\n",
      "1200/1200 [==============================] - 5s 4ms/sample - loss: 4.4808e-04 - acc: 1.0000 - val_loss: 0.9547 - val_acc: 0.7694\n",
      "iteration: 4 x_train_attack shape: (2400, 28, 28, 1) y_train_attack shape: (2400, 10)\n",
      "Train on 2400 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.4029 - acc: 0.9003\n",
      "Epoch 00001: val_acc did not improve from 0.77970\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 0.4035 - acc: 0.8992 - val_loss: 0.7916 - val_acc: 0.7531\n",
      "Epoch 2/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.2155 - acc: 0.9295\n",
      "Epoch 00002: val_acc did not improve from 0.77970\n",
      "2400/2400 [==============================] - 6s 3ms/sample - loss: 0.2135 - acc: 0.9300 - val_loss: 0.7960 - val_acc: 0.7602\n",
      "Epoch 3/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9582\n",
      "Epoch 00003: val_acc improved from 0.77970 to 0.79850, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 0.1205 - acc: 0.9579 - val_loss: 0.6552 - val_acc: 0.7985\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9789\n",
      "Epoch 00004: val_acc did not improve from 0.79850\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 0.0628 - acc: 0.9783 - val_loss: 0.7018 - val_acc: 0.7907\n",
      "Epoch 5/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9873\n",
      "Epoch 00005: val_acc did not improve from 0.79850\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 0.0416 - acc: 0.9875 - val_loss: 0.8515 - val_acc: 0.7621\n",
      "Epoch 6/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9928\n",
      "Epoch 00006: val_acc improved from 0.79850 to 0.80680, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 0.0245 - acc: 0.9929 - val_loss: 0.6812 - val_acc: 0.8068\n",
      "Epoch 7/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9949\n",
      "Epoch 00007: val_acc improved from 0.80680 to 0.82300, saving model to model/best_mnist_model_surrogate_Black.h5\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 0.0164 - acc: 0.9950 - val_loss: 0.6260 - val_acc: 0.8230\n",
      "Epoch 8/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9890\n",
      "Epoch 00008: val_acc did not improve from 0.82300\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 0.0344 - acc: 0.9892 - val_loss: 0.7798 - val_acc: 0.7921\n",
      "Epoch 9/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9983\n",
      "Epoch 00009: val_acc did not improve from 0.82300\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 0.0074 - acc: 0.9983 - val_loss: 0.7848 - val_acc: 0.7950\n",
      "Epoch 10/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9899\n",
      "Epoch 00010: val_acc did not improve from 0.82300\n",
      "2400/2400 [==============================] - 6s 3ms/sample - loss: 0.0397 - acc: 0.9896 - val_loss: 0.9654 - val_acc: 0.7392\n",
      "Epoch 11/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9970\n",
      "Epoch 00011: val_acc did not improve from 0.82300\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 0.0133 - acc: 0.9971 - val_loss: 0.8463 - val_acc: 0.7786\n",
      "Epoch 12/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9920\n",
      "Epoch 00012: val_acc did not improve from 0.82300\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 0.0266 - acc: 0.9921 - val_loss: 0.7516 - val_acc: 0.7922\n",
      "Epoch 13/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9962\n",
      "Epoch 00013: val_acc did not improve from 0.82300\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 0.0163 - acc: 0.9962 - val_loss: 0.8550 - val_acc: 0.7809\n",
      "Epoch 14/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9962\n",
      "Epoch 00014: val_acc did not improve from 0.82300\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 0.0155 - acc: 0.9962 - val_loss: 0.9653 - val_acc: 0.7627\n",
      "Epoch 15/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9958\n",
      "Epoch 00015: val_acc did not improve from 0.82300\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 0.0101 - acc: 0.9958 - val_loss: 0.7276 - val_acc: 0.8041\n",
      "Epoch 16/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9996\n",
      "Epoch 00016: val_acc did not improve from 0.82300\n",
      "2400/2400 [==============================] - 6s 3ms/sample - loss: 0.0035 - acc: 0.9996 - val_loss: 0.8440 - val_acc: 0.7887\n",
      "Epoch 17/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992\n",
      "Epoch 00017: val_acc did not improve from 0.82300\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 0.0024 - acc: 0.9992 - val_loss: 0.8829 - val_acc: 0.7869\n",
      "Epoch 18/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 4.3035e-04 - acc: 1.0000\n",
      "Epoch 00018: val_acc did not improve from 0.82300\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 4.3103e-04 - acc: 1.0000 - val_loss: 0.8803 - val_acc: 0.7902\n",
      "Epoch 19/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 2.4556e-04 - acc: 1.0000\n",
      "Epoch 00019: val_acc did not improve from 0.82300\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 2.4598e-04 - acc: 1.0000 - val_loss: 0.8890 - val_acc: 0.7888\n",
      "Epoch 20/20\n",
      "2368/2400 [============================>.] - ETA: 0s - loss: 1.9514e-04 - acc: 1.0000\n",
      "Epoch 00020: val_acc did not improve from 0.82300\n",
      "2400/2400 [==============================] - 7s 3ms/sample - loss: 1.9301e-04 - acc: 1.0000 - val_loss: 0.8926 - val_acc: 0.7879\n",
      "iteration: 5 x_train_attack shape: (4800, 28, 28, 1) y_train_attack shape: (4800, 10)\n",
      "Train on 4800 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.3519 - acc: 0.9010\n",
      "Epoch 00001: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 10s 2ms/sample - loss: 0.3516 - acc: 0.9013 - val_loss: 0.7750 - val_acc: 0.7639\n",
      "Epoch 2/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.1714 - acc: 0.9415\n",
      "Epoch 00002: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 9s 2ms/sample - loss: 0.1708 - acc: 0.9421 - val_loss: 0.6667 - val_acc: 0.7889\n",
      "Epoch 3/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9717\n",
      "Epoch 00003: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 9s 2ms/sample - loss: 0.0830 - acc: 0.9721 - val_loss: 0.8657 - val_acc: 0.7562\n",
      "Epoch 4/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9818\n",
      "Epoch 00004: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 10s 2ms/sample - loss: 0.0535 - acc: 0.9819 - val_loss: 0.7908 - val_acc: 0.7804\n",
      "Epoch 5/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9939\n",
      "Epoch 00005: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 9s 2ms/sample - loss: 0.0223 - acc: 0.9937 - val_loss: 0.8168 - val_acc: 0.7869\n",
      "Epoch 6/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9945\n",
      "Epoch 00006: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 9s 2ms/sample - loss: 0.0169 - acc: 0.9946 - val_loss: 1.1254 - val_acc: 0.7353\n",
      "Epoch 7/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9928\n",
      "Epoch 00007: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 9s 2ms/sample - loss: 0.0228 - acc: 0.9925 - val_loss: 1.0335 - val_acc: 0.7680\n",
      "Epoch 8/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9975\n",
      "Epoch 00008: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 9s 2ms/sample - loss: 0.0114 - acc: 0.9975 - val_loss: 1.0964 - val_acc: 0.7537\n",
      "Epoch 9/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9975\n",
      "Epoch 00009: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 10s 2ms/sample - loss: 0.0084 - acc: 0.9975 - val_loss: 1.1502 - val_acc: 0.7559\n",
      "Epoch 10/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9975\n",
      "Epoch 00010: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 9s 2ms/sample - loss: 0.0080 - acc: 0.9975 - val_loss: 0.9063 - val_acc: 0.7872\n",
      "Epoch 11/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9943\n",
      "Epoch 00011: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 9s 2ms/sample - loss: 0.0178 - acc: 0.9944 - val_loss: 0.9579 - val_acc: 0.7735\n",
      "Epoch 12/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9958\n",
      "Epoch 00012: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 9s 2ms/sample - loss: 0.0143 - acc: 0.9958 - val_loss: 1.0561 - val_acc: 0.7590\n",
      "Epoch 13/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9958\n",
      "Epoch 00013: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 10s 2ms/sample - loss: 0.0176 - acc: 0.9958 - val_loss: 1.1477 - val_acc: 0.7343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9962\n",
      "Epoch 00014: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 10s 2ms/sample - loss: 0.0165 - acc: 0.9960 - val_loss: 1.0137 - val_acc: 0.7575\n",
      "Epoch 15/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9962\n",
      "Epoch 00015: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 9s 2ms/sample - loss: 0.0151 - acc: 0.9960 - val_loss: 1.1223 - val_acc: 0.7404\n",
      "Epoch 16/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9960\n",
      "Epoch 00016: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 9s 2ms/sample - loss: 0.0125 - acc: 0.9960 - val_loss: 1.1655 - val_acc: 0.7478\n",
      "Epoch 17/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9996\n",
      "Epoch 00017: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 10s 2ms/sample - loss: 0.0026 - acc: 0.9996 - val_loss: 1.0789 - val_acc: 0.7810\n",
      "Epoch 18/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9996\n",
      "Epoch 00018: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 10s 2ms/sample - loss: 0.0033 - acc: 0.9996 - val_loss: 1.1788 - val_acc: 0.7614\n",
      "Epoch 19/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 3.3172e-04 - acc: 1.0000\n",
      "Epoch 00019: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 9s 2ms/sample - loss: 3.2822e-04 - acc: 1.0000 - val_loss: 1.1968 - val_acc: 0.7649\n",
      "Epoch 20/20\n",
      "4736/4800 [============================>.] - ETA: 0s - loss: 1.4810e-04 - acc: 1.0000\n",
      "Epoch 00020: val_acc did not improve from 0.82300\n",
      "4800/4800 [==============================] - 10s 2ms/sample - loss: 1.4886e-04 - acc: 1.0000 - val_loss: 1.1854 - val_acc: 0.7692\n",
      "iteration: 6 x_train_attack shape: (9600, 28, 28, 1) y_train_attack shape: (9600, 10)\n",
      "Train on 9600 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.2665 - acc: 0.9262\n",
      "Epoch 00001: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 14s 1ms/sample - loss: 0.2670 - acc: 0.9258 - val_loss: 1.1530 - val_acc: 0.6677\n",
      "Epoch 2/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9585\n",
      "Epoch 00002: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 15s 2ms/sample - loss: 0.1251 - acc: 0.9583 - val_loss: 1.0325 - val_acc: 0.7068\n",
      "Epoch 3/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9788\n",
      "Epoch 00003: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 15s 2ms/sample - loss: 0.0637 - acc: 0.9789 - val_loss: 0.9976 - val_acc: 0.7270\n",
      "Epoch 4/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9888\n",
      "Epoch 00004: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 14s 1ms/sample - loss: 0.0323 - acc: 0.9889 - val_loss: 1.1726 - val_acc: 0.7499\n",
      "Epoch 5/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9936\n",
      "Epoch 00005: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 16s 2ms/sample - loss: 0.0197 - acc: 0.9936 - val_loss: 0.9154 - val_acc: 0.7765\n",
      "Epoch 6/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9967\n",
      "Epoch 00006: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 14s 1ms/sample - loss: 0.0136 - acc: 0.9968 - val_loss: 0.9678 - val_acc: 0.7827\n",
      "Epoch 7/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9965\n",
      "Epoch 00007: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 16s 2ms/sample - loss: 0.0146 - acc: 0.9966 - val_loss: 0.7954 - val_acc: 0.7910\n",
      "Epoch 8/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9958\n",
      "Epoch 00008: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 14s 1ms/sample - loss: 0.0150 - acc: 0.9958 - val_loss: 0.8319 - val_acc: 0.8011\n",
      "Epoch 9/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9940\n",
      "Epoch 00009: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 15s 2ms/sample - loss: 0.0220 - acc: 0.9939 - val_loss: 1.5425 - val_acc: 0.6844\n",
      "Epoch 10/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9924\n",
      "Epoch 00010: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 15s 2ms/sample - loss: 0.0275 - acc: 0.9925 - val_loss: 1.0826 - val_acc: 0.7472\n",
      "Epoch 11/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9939\n",
      "Epoch 00011: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 14s 1ms/sample - loss: 0.0190 - acc: 0.9940 - val_loss: 0.9932 - val_acc: 0.7593\n",
      "Epoch 12/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9928\n",
      "Epoch 00012: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 16s 2ms/sample - loss: 0.0230 - acc: 0.9928 - val_loss: 1.3473 - val_acc: 0.7233\n",
      "Epoch 13/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9951\n",
      "Epoch 00013: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 14s 1ms/sample - loss: 0.0186 - acc: 0.9951 - val_loss: 0.9496 - val_acc: 0.7798\n",
      "Epoch 14/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9922\n",
      "Epoch 00014: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 16s 2ms/sample - loss: 0.0243 - acc: 0.9922 - val_loss: 0.8974 - val_acc: 0.7659\n",
      "Epoch 15/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9931\n",
      "Epoch 00015: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 14s 1ms/sample - loss: 0.0288 - acc: 0.9931 - val_loss: 1.1143 - val_acc: 0.7467\n",
      "Epoch 16/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9991\n",
      "Epoch 00016: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 14s 1ms/sample - loss: 0.0046 - acc: 0.9990 - val_loss: 1.0408 - val_acc: 0.7783\n",
      "Epoch 17/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9999\n",
      "Epoch 00017: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 16s 2ms/sample - loss: 0.0013 - acc: 0.9999 - val_loss: 1.1468 - val_acc: 0.7703\n",
      "Epoch 18/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 1.5454e-04 - acc: 1.0000\n",
      "Epoch 00018: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 14s 1ms/sample - loss: 1.5459e-04 - acc: 1.0000 - val_loss: 1.1781 - val_acc: 0.7715\n",
      "Epoch 19/20\n",
      "9472/9600 [============================>.] - ETA: 0s - loss: 9.3194e-05 - acc: 1.0000\n",
      "Epoch 00019: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 14s 2ms/sample - loss: 9.3033e-05 - acc: 1.0000 - val_loss: 1.2023 - val_acc: 0.7717\n",
      "Epoch 20/20\n",
      "9536/9600 [============================>.] - ETA: 0s - loss: 6.9430e-05 - acc: 1.0000\n",
      "Epoch 00020: val_acc did not improve from 0.82300\n",
      "9600/9600 [==============================] - 15s 2ms/sample - loss: 6.9308e-05 - acc: 1.0000 - val_loss: 1.2218 - val_acc: 0.7716\n",
      "iteration: 7 x_train_attack shape: (19200, 28, 28, 1) y_train_attack shape: (19200, 10)\n",
      "Train on 19200 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.2414 - acc: 0.9301\n",
      "Epoch 00001: val_acc did not improve from 0.82300\n",
      "19200/19200 [==============================] - 25s 1ms/sample - loss: 0.2411 - acc: 0.9301 - val_loss: 1.0642 - val_acc: 0.7399\n",
      "Epoch 2/20\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9661\n",
      "Epoch 00002: val_acc did not improve from 0.82300\n",
      "19200/19200 [==============================] - 27s 1ms/sample - loss: 0.1001 - acc: 0.9660 - val_loss: 1.1194 - val_acc: 0.6980\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9852\n",
      "Epoch 00003: val_acc did not improve from 0.82300\n",
      "19200/19200 [==============================] - 26s 1ms/sample - loss: 0.0450 - acc: 0.9852 - val_loss: 1.3314 - val_acc: 0.7392\n",
      "Epoch 4/20\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9914\n",
      "Epoch 00004: val_acc did not improve from 0.82300\n",
      "19200/19200 [==============================] - 26s 1ms/sample - loss: 0.0312 - acc: 0.9914 - val_loss: 1.2323 - val_acc: 0.7354\n",
      "Epoch 5/20\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9959\n",
      "Epoch 00005: val_acc did not improve from 0.82300\n",
      "19200/19200 [==============================] - 26s 1ms/sample - loss: 0.0165 - acc: 0.9959 - val_loss: 1.4192 - val_acc: 0.7606\n",
      "Epoch 6/20\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9937\n",
      "Epoch 00006: val_acc did not improve from 0.82300\n",
      "19200/19200 [==============================] - 26s 1ms/sample - loss: 0.0215 - acc: 0.9937 - val_loss: 1.0671 - val_acc: 0.7439\n",
      "Epoch 7/20\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9940\n",
      "Epoch 00007: val_acc did not improve from 0.82300\n",
      "19200/19200 [==============================] - 27s 1ms/sample - loss: 0.0186 - acc: 0.9941 - val_loss: 1.1479 - val_acc: 0.7542\n",
      "Epoch 8/20\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9904\n",
      "Epoch 00008: val_acc did not improve from 0.82300\n",
      "19200/19200 [==============================] - 25s 1ms/sample - loss: 0.0299 - acc: 0.9904 - val_loss: 0.9939 - val_acc: 0.7744\n",
      "Epoch 9/20\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9969\n",
      "Epoch 00009: val_acc did not improve from 0.82300\n",
      "19200/19200 [==============================] - 27s 1ms/sample - loss: 0.0120 - acc: 0.9968 - val_loss: 1.1888 - val_acc: 0.7544\n",
      "Epoch 10/20\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9984\n",
      "Epoch 00010: val_acc did not improve from 0.82300\n",
      "19200/19200 [==============================] - 24s 1ms/sample - loss: 0.0061 - acc: 0.9984 - val_loss: 1.3048 - val_acc: 0.7496\n",
      "Epoch 11/20\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9925\n",
      "Epoch 00011: val_acc did not improve from 0.82300\n",
      "19200/19200 [==============================] - 26s 1ms/sample - loss: 0.0236 - acc: 0.9925 - val_loss: 4.2224 - val_acc: 0.5187\n",
      "Epoch 12/20\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9908\n",
      "Epoch 00012: val_acc did not improve from 0.82300\n",
      "19200/19200 [==============================] - 25s 1ms/sample - loss: 0.0313 - acc: 0.9907 - val_loss: 1.5429 - val_acc: 0.6547\n",
      "Epoch 13/20\n",
      "19136/19200 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9953\n",
      "Epoch 00013: val_acc did not improve from 0.82300\n",
      "19200/19200 [==============================] - 26s 1ms/sample - loss: 0.0144 - acc: 0.9954 - val_loss: 1.0386 - val_acc: 0.7504\n",
      "Epoch 14/20\n",
      "76736/76800 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9964\n",
      "Epoch 00016: val_acc did not improve from 0.82300\n",
      "76800/76800 [==============================] - 93s 1ms/sample - loss: 0.0146 - acc: 0.9964 - val_loss: 1.2529 - val_acc: 0.7724\n",
      "Epoch 17/20\n",
      "76736/76800 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9955\n",
      "Epoch 00017: val_acc did not improve from 0.82300\n",
      "76800/76800 [==============================] - 88s 1ms/sample - loss: 0.0175 - acc: 0.9955 - val_loss: 1.7411 - val_acc: 0.7453\n",
      "Epoch 18/20\n",
      "76736/76800 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9966\n",
      "Epoch 00018: val_acc did not improve from 0.82300\n",
      "76800/76800 [==============================] - 97s 1ms/sample - loss: 0.0125 - acc: 0.9966 - val_loss: 1.8900 - val_acc: 0.7350\n",
      "Epoch 19/20\n",
      "76736/76800 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9956\n",
      "Epoch 00019: val_acc did not improve from 0.82300\n",
      "76800/76800 [==============================] - 97s 1ms/sample - loss: 0.0181 - acc: 0.9956 - val_loss: 1.6290 - val_acc: 0.7635\n",
      "Epoch 20/20\n",
      "76736/76800 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9967\n",
      "Epoch 00020: val_acc did not improve from 0.82300\n",
      "76800/76800 [==============================] - 95s 1ms/sample - loss: 0.0124 - acc: 0.9967 - val_loss: 1.9243 - val_acc: 0.7454\n"
     ]
    }
   ],
   "source": [
    "model_surrogate, history_list = Practical_black_box_attach(model_surrogate_fun = get_lenet_model_for_mnist,\n",
    "                               x_train_attack = x_train_attack,\n",
    "                               y_train_attack = y_train_attack,\n",
    "                               x_test = x_test,\n",
    "                               y_test = y_test,\n",
    "                               lambda_update = 1,\n",
    "                               num_iter = 10,\n",
    "                               eval_metric = 'acc',\n",
    "                               delta = 0.01,\n",
    "                               path_store_surrogate_model = 'model/best_mnist_model_surrogate_Black.h5',\n",
    "                               batch_size_train = 64,\n",
    "                               batch_size_eval = 1024,\n",
    "                               epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 83us/sample - loss: 1.1226 - acc: 0.7063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1225852348327636, 0.7063]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_surrogate.evaluate(x_test, y_test, batch_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
